"""
Rule synthesis module.

Uses LLM (OpenAI) to transform raw patterns into well-written, actionable rules.
Falls back to basic synthesis if no API key is available.
"""

import os
from datetime import datetime
from typing import Optional

from .filters import clean_text


SYNTHESIS_PROMPT = """You are helping a developer create personalized rules for their AI coding assistant (Cursor).

Based on their chat history patterns, synthesize clear, actionable rules. The patterns below show what instructions they frequently give.

PATTERNS DETECTED:
{patterns}

FREQUENTLY REPEATED PHRASES:
{phrases}

SIMILAR MESSAGE CLUSTERS:
{clusters}

Generate well-organized cursor rules in markdown format. Guidelines:
1. Group related rules under clear category headers (## Deployment, ## Code Quality, etc.)
2. Write rules as clear, imperative statements ("Push to GitHub after every change", not "User wants to push to GitHub")
3. Combine similar patterns into single, comprehensive rules
4. Be concise - each rule should be 1-2 sentences max
5. Focus on actionable behaviors, not vague preferences
6. Include specific details from the examples when relevant
7. Skip any patterns that seem like noise or one-off requests

Output ONLY the markdown rules, no explanations or preamble."""


def synthesize_rules(patterns: dict, phrases: list, clusters: list) -> Optional[str]:
    """
    Use OpenAI to synthesize patterns into well-written rules.
    
    Args:
        patterns: Dictionary of detected patterns
        phrases: List of (phrase, count) tuples
        clusters: List of similar message groups
        
    Returns:
        Synthesized rules as markdown string, or None if LLM unavailable
    """
    # Check for API key
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        # Also check common Cursor locations
        api_key = os.environ.get("CURSOR_OPENAI_API_KEY")
    
    if not api_key:
        return None
    
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
    except ImportError:
        return None
    except Exception:
        return None
    
    # Format patterns for prompt
    patterns_text = ""
    for name, data in list(patterns.items())[:10]:
        label = data.get('label', name)
        count = data['count']
        examples = data.get('examples', [])[:3]
        
        patterns_text += f"\n### {label} ({count} occurrences)\n"
        for ex in examples:
            clean_ex = clean_text(ex)[:150]
            patterns_text += f"- \"{clean_ex}\"\n"
    
    # Format phrases
    phrases_text = ""
    for phrase, count in phrases[:10]:
        phrases_text += f"- ({count}x) \"{phrase}\"\n"
    
    # Format clusters
    clusters_text = ""
    for i, cluster in enumerate(clusters[:5], 1):
        clusters_text += f"\nCluster {i} ({len(cluster)} similar messages):\n"
        for msg in cluster[:3]:
            clean_msg = clean_text(msg)[:100]
            clusters_text += f"- \"{clean_msg}\"\n"
    
    prompt = SYNTHESIS_PROMPT.format(
        patterns=patterns_text or "None detected",
        phrases=phrases_text or "None detected",
        clusters=clusters_text or "None detected",
    )
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Fast and cheap
            messages=[
                {"role": "system", "content": "You are a helpful assistant that creates clear, actionable rules for AI coding assistants."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000,
        )
        
        content = response.choices[0].message.content
        
        # Add header
        header = f"""# Cursor Rules
# Generated by cursorhabits on {datetime.now().strftime('%Y-%m-%d %H:%M')}
# Synthesized from your chat history patterns

"""
        return header + content
        
    except Exception as e:
        # Silently fail and return None to trigger fallback
        return None


def synthesize_rules_basic(patterns: dict, phrases: list) -> str:
    """
    Generate rules without LLM (basic template-based approach).
    
    Args:
        patterns: Dictionary of detected patterns
        phrases: List of (phrase, count) tuples
        
    Returns:
        Basic rules as markdown string
    """
    lines = [
        "# Cursor Rules",
        f"# Generated by cursorhabits on {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
    ]
    
    # Map pattern names to rule templates
    rule_templates = {
        'github_push': ('Deployment', 'Push to GitHub after every meaningful change - don\'t wait to be asked'),
        'vercel_deploy': ('Deployment', 'Deploy to Vercel and test on production URL, not localhost'),
        'update_docs': ('Documentation', 'Update README/docs with current state after significant changes'),
        'mobile_check': ('Quality', 'Always evaluate how changes look on mobile before considering done'),
        'no_fallbacks': ('Error Handling', 'No silent error handling - log errors clearly, then throw'),
        'check_before': ('Planning', 'Think before implementing - explain approach first for complex tasks'),
        'api_keys': ('Environment', 'When user provides API keys, add to .env immediately and confirm'),
        'be_concise': ('Communication', 'Be concise - don\'t over-explain, focus on actionable information'),
        'verify_data': ('Quality', 'Verify all calculations - trace at least one example end-to-end'),
        'comment_code': ('Quality', 'Comment code for external developers - explain the "why"'),
        'user_perspective': ('Quality', 'Always consider the real user experience - what would they actually see?'),
        'clean_code': ('Quality', 'Clean up as you go - remove dead code, archive outdated content'),
    }
    
    # Group by category
    categories = {}
    for name, data in patterns.items():
        if name in rule_templates:
            category, rule = rule_templates[name]
            if category not in categories:
                categories[category] = []
            categories[category].append({
                'rule': rule,
                'count': data['count'],
            })
        else:
            # Use first example as rule
            label = data.get('label', name.replace('_', ' ').title())
            examples = data.get('examples', [])
            if examples:
                if label not in categories:
                    categories[label] = []
                example_rule = clean_text(examples[0])
                if len(example_rule) > 100:
                    example_rule = example_rule[:97] + "..."
                categories[label].append({
                    'rule': example_rule,
                    'count': data['count'],
                })
    
    # Output categories
    for category, rules in categories.items():
        total_count = sum(r['count'] for r in rules)
        lines.append(f"## {category}")
        lines.append("")
        
        for r in rules:
            lines.append(f"- {r['rule']}")
        
        lines.append("")
    
    # Add repeated phrases as potential rules
    if phrases:
        lines.append("## Frequently Repeated")
        lines.append("*These phrases appeared often - consider if they should be rules:*")
        lines.append("")
        
        for phrase, count in phrases[:8]:
            lines.append(f"- ({count}x) \"{phrase}\"")
        
        lines.append("")
    
    # Add tips
    lines.append("---")
    lines.append("")
    lines.append("*Copy these rules to Cursor Settings â†’ Rules for AI, or run `cursorhabits apply`*")
    
    return '\n'.join(lines)

